{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR6j/qLVNJ1NlbR3ne2ZNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batool-sajdi/project_for_prects/blob/main/LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "y1cXsO98qUeE"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n"
      ],
      "metadata": {
        "id": "vBxpFxy82zdU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"online-rag-project\"  # change if desired\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)\n"
      ],
      "metadata": {
        "id": "iHrNGwUKqb8H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ],
      "metadata": {
        "id": "r63Jto898O5i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"i am bilding project \")"
      ],
      "metadata": {
        "id": "GSvNzY2yAO-3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4nwVLwf6VR",
        "outputId": "2e78f4c7-1b20-4597-f25b-0314c251a67b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.011388907209038734, 0.011589575558900833, -0.03647366538643837]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "b2QU6Td-h4yi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")"
      ],
      "metadata": {
        "id": "WaxMM_QVjBF0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vscX3xZmjJS_",
        "outputId": "69c8dec7-47d4-4221-baae-4ce219ad95cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n"
      ],
      "metadata": {
        "id": "4KoXqZSOi8Sy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)\n",
        "\n",
        "# data retereve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPhMnn73jm5s",
        "outputId": "c03c8562-725c-4165-e57b-70d1b3f86b12"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f5f801c2-ca62-44e2-a67e-e091ddbeb3df',\n",
              " 'dc752af0-a571-42f8-bbe3-dccc4256c1f2',\n",
              " '234f3a0d-a8ee-48b3-8472-6e188b234817',\n",
              " 'e6e82947-9bc5-497d-b02d-b6ef40e8d1fb',\n",
              " '198d09c6-d308-43da-8b1a-909e49bd491d',\n",
              " 'cd79f679-1f65-430b-a7dc-90b3ce478734',\n",
              " 'a88e3149-9600-4d43-8f1e-72cae9ed5e26',\n",
              " '8da7ceec-4839-44ad-b522-b9ade991dffa',\n",
              " '137ee5df-7bce-47dc-b675-6c7e0ab0d61c',\n",
              " 'ab2ac24f-3e20-465e-8511-1739f12ee02f']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"The top 10 soccer players in the world right now.\",\n",
        "    k=2,\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMwXRM8kMjL",
        "outputId": "100f09ea-339c-4f60-aa1c-791f2c55be3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* The top 10 soccer players in the world right now. [{'source': 'website'}]\n",
            "* The top 10 soccer players in the world right now. [{'source': 'website'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMMNxh6pkHel",
        "outputId": "d9f213de-eee5-423f-de4c-f0ba22f5f376"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Is the new iPhone worth the price? Read this review to find out.\", k=1, filter={\"source\": \"website\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b19iW9osk3tH",
        "outputId": "1ab4ee08-ecff-4707-e5ca-055b97b66195"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.807020] Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-generativeai"
      ],
      "metadata": {
        "id": "t2-QfGYyx0cR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "def answer_to_user(query: str):\n",
        "    # Vector Search\n",
        "    Vector_results = vector_store.similarity_search(query, k=2)\n",
        "    print(len(Vector_results))\n",
        "\n",
        "    # Pass to Model Vector Results + User Query\n",
        "    # Use generate_message instead of invoke and generate_text\n",
        "    final_answer = llm.generate_message(\n",
        "        prompt=f\"ANSWER THIS USER QUERY:{query},HERE ARE SOME REFERNCES  TO ANWSER {Vector_results} \"\n",
        "    )\n",
        "    # Remove the unnecessary and incorrect line\n",
        "    # ChatGoogleGenerativeAI(results, query)\n",
        "    return final_answer.text  # Access the text content of the response"
      ],
      "metadata": {
        "id": "R7I8inXcyBvR"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "VYYqp_26tlMs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_to_user(query: str):\n",
        "    # Vector Search\n",
        "    Vector_results = vector_store.similarity_search(query, k=2)\n",
        "    print(len(Vector_results))\n",
        "\n",
        "\n",
        "    # Pass to Model Vector Results + User Query\n",
        "    final_answer = llm.invoke(f\"ANSWER THIS USER QUERY:{query},HERE ARE SOME REFERNCES  TO ANWSER {Vector_results} \")\n",
        "    ChatGoogleGenerativeAI(results, query)\n",
        "\n",
        "    return final_answer\n"
      ],
      "metadata": {
        "id": "P5mhF9VlmdwP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_to_user(query: str):\n",
        "    # Vector Search\n",
        "    Vector_results = vector_store.similarity_search(query, k=2)\n",
        "    print(len(Vector_results))\n",
        "\n",
        "\n",
        "    # Pass to Model Vector Results + User Query\n",
        "    final_answer = llm.invoke(f\"ANSWER THIS USER QUERY:{query},HERE ARE SOME REFERNCES  TO ANWSER {Vector_results} \")\n",
        "    # Remove this line causing error, it's not needed\n",
        "    # ChatGoogleGenerativeAI(results, query)\n",
        "\n",
        "    return final_answer"
      ],
      "metadata": {
        "id": "cC-HFLp4ysGn"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " answer = answer_to_user(\"what is langchain ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NZBhLm7w2JO",
        "outputId": "e891af35-748d-4b3d-c044-b8d74215b9f5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9Rm5RRQlyyb8",
        "outputId": "dc861e2c-27fb-4675-ba91-c24060f19dd6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided text, LangChain is a framework used for building projects.  The tweets suggest it's something people are using to create exciting new projects, but no further details about its functionality are given.  More information would be needed to provide a complete definition.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ]
}